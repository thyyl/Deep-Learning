{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasCallbacks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V5nNmO-aqkY"
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from matplotlib import pyplot\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import load_model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ub-uEi6cGiw"
      },
      "source": [
        "### Based Line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "yzEmbGxtbfoD",
        "outputId": "d27a6054-c8d1-4d1b-e801-67141b40ff3c"
      },
      "source": [
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "n_train = 30\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0)\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 1.000, Test: 0.914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daSWkiixcEDn"
      },
      "source": [
        "### Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "kGmavTpycJgn",
        "outputId": "b5299a91-1e11-40a7-a825-0a4801586c5d"
      },
      "source": [
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "\n",
        "n_train = 30\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
        "\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 00245: early stopping\n",
            "Train: 0.967, Test: 0.814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mMtIftfcXAL"
      },
      "source": [
        "Early stopping with patience"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "aMRnAz4AcZdP",
        "outputId": "d210eb45-6bc1-4be1-d93b-284ee902d07c"
      },
      "source": [
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "n_train = 30\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "\n",
        "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 00962: early stopping\n",
            "Train: 1.000, Test: 0.943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOVU-aQmctOO"
      },
      "source": [
        "### Model Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtPSk046cu56",
        "outputId": "428005b5-9d34-4605-89f9-cdbd39d3b581"
      },
      "source": [
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "n_train = 30\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es, mc])\n",
        "saved_model = load_model('best_model.h5')\n",
        "_, train_acc = saved_model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = saved_model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.55714, saving model to best_model.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.55714 to 0.62857, saving model to best_model.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.62857 to 0.64286, saving model to best_model.h5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.64286 to 0.67143, saving model to best_model.h5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.67143 to 0.68571, saving model to best_model.h5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.68571\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.68571 to 0.71429, saving model to best_model.h5\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.71429 to 0.72857, saving model to best_model.h5\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.72857 to 0.74286, saving model to best_model.h5\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 00109: val_accuracy improved from 0.74286 to 0.75714, saving model to best_model.h5\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 00120: val_accuracy improved from 0.75714 to 0.78571, saving model to best_model.h5\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.78571\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.78571 to 0.80000, saving model to best_model.h5\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.80000 to 0.81429, saving model to best_model.h5\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 00140: val_accuracy improved from 0.81429 to 0.82857, saving model to best_model.h5\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 00288: val_accuracy improved from 0.82857 to 0.84286, saving model to best_model.h5\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00501: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00502: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00503: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00504: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00505: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00506: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00507: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00508: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00509: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00510: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00511: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00512: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00513: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00514: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00515: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00516: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00517: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00518: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00519: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00520: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00521: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00522: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00523: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00524: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00525: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00526: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00527: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00528: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00529: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00530: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00531: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00532: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00533: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00534: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00535: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00536: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00537: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00538: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00539: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00540: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00541: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00542: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00543: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00544: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00545: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00546: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00547: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00548: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00549: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00550: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00551: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00552: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00553: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00554: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00555: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00556: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00557: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00558: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00559: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00560: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00561: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00562: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00563: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00564: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 00565: val_accuracy improved from 0.84286 to 0.85714, saving model to best_model.h5\n",
            "\n",
            "Epoch 00566: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 00567: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 00568: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 00569: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 00570: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 00571: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 00572: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 00573: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 00574: val_accuracy improved from 0.85714 to 0.87143, saving model to best_model.h5\n",
            "\n",
            "Epoch 00575: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 00576: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 00577: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 00578: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 00579: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 00580: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 00581: val_accuracy improved from 0.87143 to 0.88571, saving model to best_model.h5\n",
            "\n",
            "Epoch 00582: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00583: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00584: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00585: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00586: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00587: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00588: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00589: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00590: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00591: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00592: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00593: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00594: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00595: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00596: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00597: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00598: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00599: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00600: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00601: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00602: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00603: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00604: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00605: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00606: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00607: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00608: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00609: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 00610: val_accuracy improved from 0.88571 to 0.90000, saving model to best_model.h5\n",
            "\n",
            "Epoch 00611: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00612: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00613: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00614: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00615: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00616: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00617: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00618: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00619: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00620: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00621: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00622: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00623: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00624: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00625: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00626: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00627: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00628: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00629: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00630: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00631: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00632: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00633: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00634: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00635: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00636: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00637: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00638: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00639: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00640: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00641: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00642: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00643: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00644: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00645: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00646: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00647: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00648: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00649: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00650: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00651: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00652: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00653: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00654: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00655: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00656: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00657: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00658: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00659: val_accuracy improved from 0.90000 to 0.91429, saving model to best_model.h5\n",
            "\n",
            "Epoch 00660: val_accuracy did not improve from 0.91429\n",
            "\n",
            "Epoch 00661: val_accuracy did not improve from 0.91429\n",
            "\n",
            "Epoch 00662: val_accuracy did not improve from 0.91429\n",
            "\n",
            "Epoch 00663: val_accuracy did not improve from 0.91429\n",
            "\n",
            "Epoch 00664: val_accuracy did not improve from 0.91429\n",
            "\n",
            "Epoch 00665: val_accuracy did not improve from 0.91429\n",
            "\n",
            "Epoch 00666: val_accuracy did not improve from 0.91429\n",
            "\n",
            "Epoch 00667: val_accuracy improved from 0.91429 to 0.92857, saving model to best_model.h5\n",
            "\n",
            "Epoch 00668: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00669: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00670: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00671: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00672: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00673: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00674: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00675: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00676: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00677: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00678: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00679: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00680: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00681: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00682: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00683: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00684: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00685: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00686: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00687: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00688: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00689: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00690: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00691: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00692: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00693: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00694: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00695: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00696: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00697: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00698: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00699: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00700: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00701: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00702: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00703: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00704: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00705: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00706: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00707: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00708: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00709: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00710: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00711: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00712: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00713: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00714: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00715: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00716: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00717: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00718: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00719: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00720: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00721: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00722: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00723: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00724: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00725: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00726: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00727: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00728: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00729: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00730: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00731: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00732: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00733: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00734: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00735: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00736: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00737: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00738: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00739: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00740: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00741: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00742: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00743: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00744: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00745: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00746: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00747: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00748: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00749: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00750: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00751: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00752: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00753: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00754: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00755: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00756: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00757: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00758: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00759: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00760: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00761: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00762: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00763: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00764: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00765: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00766: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00767: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00768: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00769: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00770: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00771: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00772: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00773: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00774: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00775: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00776: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00777: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00778: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00779: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00780: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00781: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00782: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00783: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00784: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00785: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00786: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00787: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00788: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00789: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00790: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00791: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00792: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00793: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00794: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00795: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00796: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00797: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00798: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00799: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00800: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00801: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00802: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00803: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00804: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00805: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00806: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00807: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00808: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00809: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00810: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00811: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00812: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00813: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00814: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00815: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00816: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00817: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00818: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00819: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00820: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00821: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00822: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00823: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00824: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00825: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00826: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00827: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00828: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00829: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00830: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00831: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00832: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00833: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00834: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00835: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00836: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00837: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00838: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00839: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00840: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00841: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00842: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00843: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00844: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00845: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00846: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00847: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00848: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00849: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00850: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00851: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00852: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00853: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00854: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00855: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00856: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00857: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00858: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00859: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00860: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00861: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00862: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00863: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00864: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00865: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00866: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00867: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00868: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00869: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00870: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00871: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00872: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00873: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00874: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00875: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00876: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00877: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00878: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00879: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00880: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00881: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00882: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00883: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00884: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00885: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 00886: val_accuracy improved from 0.92857 to 0.94286, saving model to best_model.h5\n",
            "\n",
            "Epoch 00887: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00888: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00889: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00890: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00891: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00892: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00893: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00894: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00895: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00896: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00897: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00898: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00899: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00900: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00901: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00902: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00903: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00904: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00905: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00906: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00907: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00908: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00909: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00910: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00911: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00912: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00913: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00914: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00915: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00916: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00917: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00918: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00919: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00920: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00921: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00922: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00923: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00924: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00925: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00926: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00927: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00928: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00929: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00930: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00931: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00932: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00933: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00934: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00935: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00936: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00937: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00938: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00939: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00940: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00941: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00942: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00943: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00944: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00945: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00946: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00947: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00948: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00949: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00950: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00951: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00952: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00953: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00954: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00955: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00956: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00957: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00958: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00959: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00960: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00961: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00962: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00963: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00964: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00965: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00966: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00967: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00968: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00969: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00970: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00971: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00972: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00973: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00974: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00975: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00976: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00977: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00978: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00979: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00980: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00981: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00982: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00983: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00984: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00985: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00986: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00987: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00988: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00989: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00990: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00991: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00992: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00993: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00994: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00995: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00996: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00997: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00998: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 00999: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01000: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01001: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01002: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01003: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01004: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01005: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01006: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01007: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01008: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01009: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01010: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01011: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01012: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01013: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01014: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01015: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01016: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01017: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01018: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01019: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01020: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01021: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01022: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01023: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01024: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01025: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01026: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01027: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01028: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01029: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01030: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01031: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01032: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01033: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01034: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01035: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01036: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01037: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01038: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01039: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 01040: val_accuracy did not improve from 0.94286\n",
            "Epoch 01040: early stopping\n",
            "Train: 1.000, Test: 0.943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6ufVvqsfxtL"
      },
      "source": [
        "### Reducing learning rate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWHMhVcIf1_j",
        "outputId": "c16c2842-b5d4-4963-cd42-a3edc88ff405"
      },
      "source": [
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "n_train = 30\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=200)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "rlop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=200)\n",
        "\n",
        "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es, mc, rlop])\n",
        "saved_model = load_model('best_model.h5')\n",
        "_, train_acc = saved_model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = saved_model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 1.000, Test: 0.943\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}